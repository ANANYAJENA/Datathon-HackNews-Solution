{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"D:/DATATHON/Task_2_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>news_text</th>\n",
       "      <th>news_number</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US bloggers banned from entering UK</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            news_text  news_number  \\\n",
       "0           0  US bloggers banned from entering UK    111111112   \n",
       "\n",
       "        news_type  \n",
       "0  non-propaganda  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.columns =['sentence_id','news_text','news_number','news_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>news_text</th>\n",
       "      <th>news_number</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US bloggers banned from entering UK</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Two prominent US bloggers have been banned fro...</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111111112</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pamela Geller and Robert Spencer co-founded an...</td>\n",
       "      <td>111111112</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                          news_text  \\\n",
       "0            0                US bloggers banned from entering UK   \n",
       "1            1                                                NaN   \n",
       "2            2  Two prominent US bloggers have been banned fro...   \n",
       "3            3                                                NaN   \n",
       "4            4  Pamela Geller and Robert Spencer co-founded an...   \n",
       "\n",
       "   news_number       news_type  \n",
       "0    111111112  non-propaganda  \n",
       "1    111111112  non-propaganda  \n",
       "2    111111112  non-propaganda  \n",
       "3    111111112  non-propaganda  \n",
       "4    111111112      propaganda  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dataframe.set_index(['sentence_id','news_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15170, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>news_text</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th>news_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>111111112</th>\n",
       "      <td>US bloggers banned from entering UK</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>111111112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>111111112</th>\n",
       "      <td>Two prominent US bloggers have been banned fro...</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 news_text  \\\n",
       "sentence_id news_number                                                      \n",
       "0           111111112                  US bloggers banned from entering UK   \n",
       "1           111111112                                                  NaN   \n",
       "2           111111112    Two prominent US bloggers have been banned fro...   \n",
       "\n",
       "                              news_type  \n",
       "sentence_id news_number                  \n",
       "0           111111112    non-propaganda  \n",
       "1           111111112    non-propaganda  \n",
       "2           111111112    non-propaganda  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news_text    907\n",
       "news_type      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-propaganda    11230\n",
       "propaganda         3940\n",
       "Name: news_type, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['news_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news_text    907\n",
       "news_type      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15170, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-propaganda    10325\n",
       "propaganda         3938\n",
       "Name: news_type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news_text    0\n",
       "news_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>news_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th>news_number</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>111111112</th>\n",
       "      <td>US bloggers banned from entering UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>111111112</th>\n",
       "      <td>Two prominent US bloggers have been banned fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 news_text\n",
       "sentence_id news_number                                                   \n",
       "0           111111112                  US bloggers banned from entering UK\n",
       "2           111111112    Two prominent US bloggers have been banned fro..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['news_type']\n",
    "df2 = df.drop('news_type',axis=1)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df2['news_text'],y,test_size =0.3, random_state= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit(X_train)\n",
    "tfidf_train = tfidf_vectorizer.transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tfidf_test.toarray())\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.733\n",
      "0.5119453924914676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# linear_clf = PassiveAggressiveClassifier(max_iter=5,tol=1e-3,random_state=1)   # F1 : 0.509 \n",
    "linear_clf = PassiveAggressiveClassifier(max_iter=9,tol = 0.0001,random_state=100) # 0.5119\n",
    "# linear_clf = PassiveAggressiveClassifier(max_iter=90,tol = 0.0001,random_state=100) # 0.489\n",
    "linear_clf.fit(tfidf_train, y_train)\n",
    "pred = linear_clf.predict(tfidf_test)\n",
    "score_pa_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_pa_tfidf = round(score_pa_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_pa_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_pa = (2*P*R)/(P+R)\n",
    "print(F1_pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.725\n",
      "0.4871459694989107\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(n_jobs=1, C=1e3)\n",
    "lr.fit(tfidf_train, y_train)\n",
    "pred = lr.predict(tfidf_test)\n",
    "score_lr_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_lr_tfidf = round(score_lr_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_lr_tfidf)\n",
    "# cm_lr_tfidf = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda'])\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_lr = (2*P*R)/(P+R)\n",
    "print(F1_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.738\n",
      "0.1290824261275272\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(tfidf_train, y_train)\n",
    "\n",
    "pred = clf.predict(tfidf_test)\n",
    "score_nb_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_nb_tfidf = round(score_nb_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_nb_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_nb_tfidf = (2*P*R)/(P+R)\n",
    "print(F1_nb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.743\n",
      "0.31910946196660483\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=100)\n",
    "rf.fit(tfidf_train, y_train)\n",
    "pred = rf.predict(tfidf_test)\n",
    "score_rf_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_rf_tfidf = round(score_rf_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_rf_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_rf = (2*P*R)/(P+R)\n",
    "print(F1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.710\n",
      "0.4274527867342239\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=100)\n",
    "dt.fit(tfidf_train, y_train)\n",
    "pred = dt.predict(tfidf_test)\n",
    "score_dt_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_dt_tfidf = round(score_dt_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_dt_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_dt = (2*P*R)/(P+R)\n",
    "print(F1_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.729\n",
      "0.23280423280423276\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(tfidf_train, y_train)\n",
    "pred = ada.predict(tfidf_test)\n",
    "score_ada_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_ada_tfidf = round(score_ada_tfidf,3)\n",
    "print(\"accuracy:   %0.3f\" % score_ada_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_ada = (2*P*R)/(P+R)\n",
    "print(F1_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.714\n",
      "0.47935291613452535\n"
     ]
    }
   ],
   "source": [
    "# mlp = MLPClassifier(hidden_layer_sizes=(5,5,4)) #0.45  (8,8,5)) # 0.48\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,10,5),activation='relu', solver='adam') # 0.48()\n",
    "mlp.fit(tfidf_train, y_train)\n",
    "pred = mlp.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_mlp_tfidf1=round(score,3)\n",
    "#print(score_knn_tfidf)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_mlp = (2*P*R)/(P+R)\n",
    "print(F1_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.720\n",
      "0.06396255850234009\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(tfidf_train, y_train)\n",
    "pred = knn.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_knn_tfidf=round(score,3)\n",
    "#print(score_knn_tfidf)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_knn = (2*P*R)/(P+R)\n",
    "print(F1_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.753\n",
      "0.3592233009708738\n"
     ]
    }
   ],
   "source": [
    "svm1 = SVC(C=1.0,gamma=1, kernel='sigmoid', random_state= 50)\n",
    "# svm1 = SVC(C=1.0,gamma=1, kernel='poly', random_state= 50)\n",
    "svm1.fit(tfidf_train, y_train)\n",
    "pred = svm1.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_svm_tfidf = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_svm_tf1 = (2*P*R)/(P+R)\n",
    "print(F1_svm_tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723066136947885"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "np.mean(predicted_svm == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.703\n",
      "0.49842022116903634\n"
     ]
    }
   ],
   "source": [
    "# svm2 = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)\n",
    "svm2 = SGDClassifier(loss='perceptron', penalty='l2',alpha=0.001, random_state=42, max_iter=5, tol=None) # 0.498\n",
    "# svm2 = SGDClassifier(loss='perceptron', penalty='elasticnet',alpha=0.001, random_state=42, max_iter=5, tol=None)\n",
    "svm2.fit(tfidf_train, y_train)\n",
    "pred = svm2.predict(tfidf_test)\n",
    "score1_svm_tfidf = metrics.accuracy_score(y_test, pred)\n",
    "score_svm_tfidf2 = round(score1,3)\n",
    "print(\"accuracy:   %0.3f\" % score1_svm_tfidf)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_svm2_tf = (2*P*R)/(P+R)\n",
    "print(F1_svm2_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>DT</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>MLP_NN</th>\n",
       "      <th>NB</th>\n",
       "      <th>Passive Aggresive</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model Accuracy_tfidf</th>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>0.703202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score_tfidf</th>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.427453</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.487146</td>\n",
       "      <td>0.479353</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.511945</td>\n",
       "      <td>0.319109</td>\n",
       "      <td>0.498420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      AdaBoost        DT       KNN  Logistic    MLP_NN  \\\n",
       "Model Accuracy_tfidf  0.729000  0.710000  0.720000  0.725000  0.714000   \n",
       "F1 Score_tfidf        0.232804  0.427453  0.063963  0.487146  0.479353   \n",
       "\n",
       "                            NB  Passive Aggresive        RF       SVM  \n",
       "Model Accuracy_tfidf  0.738000           0.733000  0.743000  0.703202  \n",
       "F1 Score_tfidf        0.129082           0.511945  0.319109  0.498420  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2 = {'Passive Aggresive':score_pa_tfidf,'Logistic':score_lr_tfidf,'AdaBoost':score_ada_tfidf,'NB':score_nb_tfidf,\n",
    "       'RF':score_rf_tfidf,'DT':score_dt_tfidf,'KNN':score_knn_tfidf,\"MLP_NN\":score_mlp_tfidf1,\"SVM\":score1_svm_tfidf}\n",
    "F1_tfidf = {'Passive Aggresive':F1_pa,'Logistic':F1_lr,'AdaBoost':F1_ada,'NB':F1_nb_tfidf,\n",
    "      'RF':F1_rf,'DT':F1_dt,'KNN':F1_knn,\"MLP_NN\":F1_mlp,\"SVM\":F1_svm2_tf}\n",
    "acc_tfidf = pd.DataFrame([acc2,F1_tfidf])\n",
    "acc_tfidf.index=['Model Accuracy_tfidf','F1 Score_tfidf']\n",
    "acc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn,fp,fn,tp = confusion_matrix(test_dy,test_pred).ravel() \n",
    "# sensitivity = (tp/(tp+fn))*100 # recall\n",
    "# specificity = (tn/(tn+fp))*100\n",
    "# accuracy = ((tp+tn)/(tp+tn+fp+fn))*100\n",
    "\n",
    "# tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "# R = (tp/(tp+fn))*100 # recall\n",
    "# P = (tp/(tp+fp))*100 # precision\n",
    "# F1 = (2*P*R)/(P+R)\n",
    "# print(tn,fp,fn,tp,sensitivity,specificity, F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit(X_train)\n",
    "count_train = count_vectorizer.transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.760\n",
      "0.5031446540880502\n"
     ]
    }
   ],
   "source": [
    "## Fitting Naive Baye's Classifier for Multinomial Model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(count_train, y_train)\n",
    "pred = clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_nb = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_nb_cnt = (2*P*R)/(P+R)\n",
    "print(F1_nb_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.732\n",
      "0.49427312775330395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:451: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## Fitting Passive Aggresive Classifier Model\n",
    "\n",
    "linear_clf = PassiveAggressiveClassifier(max_iter=11,tol = 0.0001,random_state=100)\n",
    "\n",
    "linear_clf.fit(count_train, y_train)\n",
    "pred = linear_clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_pa = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_pa_cnt = (2*P*R)/(P+R)\n",
    "print(F1_pa_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.741\n",
      "0.41167108753315645\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=100)\n",
    "rf.fit(count_train, y_train)\n",
    "pred = rf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_rf = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_rf_cnt = (2*P*R)/(P+R)\n",
    "print(F1_rf_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.725\n",
      "0.043938161106590726\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=100,max_depth=2)\n",
    "dt.fit(count_train, y_train)\n",
    "pred = dt.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_dt = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_dt_cnt = (2*P*R)/(P+R)\n",
    "print(F1_dt_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.745\n",
      "0.5058930190389845\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(n_jobs=1, C=1e5, random_state=10)\n",
    "lr.fit(count_train, y_train)\n",
    "pred = lr.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_lr = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_lr_cnt = (2*P*R)/(P+R)\n",
    "print(F1_lr_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.734\n",
      "0.2804801010739103\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(count_train, y_train)\n",
    "pred = ada.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_ada = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_ada_cnt = (2*P*R)/(P+R)\n",
    "print(F1_ada_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.727\n",
      "0.47623318385650226\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50,40)) # initially(554_0.46)  (9,9,5)) # 0.476\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(19,19,5),activation='logistic') # 0.483\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(19,19,5),activation='logistic')\n",
    "mlp.fit(count_train, y_train)\n",
    "pred = mlp.predict(count_test)\n",
    "score= metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_mlp=round(score,3)\n",
    "#print(score_knn_tfidf)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_mlp_cnt = (2*P*R)/(P+R)\n",
    "print(F1_mlp_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.678\n",
      "0.3740354062641852\n"
     ]
    }
   ],
   "source": [
    "svm1 = SVC(C=1.0,gamma=1, kernel='sigmoid', random_state= 50)\n",
    "svm1.fit(count_train, y_train)\n",
    "pred = svm1.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_svm1 = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_svm_cnt = (2*P*R)/(P+R)\n",
    "print(F1_svm_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.761\n",
      "0.38752249550089984\n"
     ]
    }
   ],
   "source": [
    "svm2 = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)\n",
    "svm2.fit(count_train, y_train)\n",
    "pred = svm2.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_svm2 = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_svm2_cnt = (2*P*R)/(P+R)\n",
    "print(F1_svm2_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.718\n",
      "0.13600572655690768\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(count_train, y_train)\n",
    "pred = knn.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "score_cnt_knn = round(score,3)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "tn,fp,fn,tp = metrics.confusion_matrix(y_test, pred, labels=['non-propaganda', 'propaganda']).ravel()\n",
    "R = (tp/(tp+fn)) # recall/sensitivity\n",
    "P = (tp/(tp+fp)) # precision\n",
    "F1_knn_cnt = (2*P*R)/(P+R)\n",
    "print(F1_knn_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>DT</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>MLP_NN</th>\n",
       "      <th>NB</th>\n",
       "      <th>Passive Aggresive</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model Accuracy_cnt</th>\n",
       "      <td>0.73400</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.718000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.71700</td>\n",
       "      <td>0.741000</td>\n",
       "      <td>0.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score_cnt</th>\n",
       "      <td>0.28048</td>\n",
       "      <td>0.043938</td>\n",
       "      <td>0.136006</td>\n",
       "      <td>0.463224</td>\n",
       "      <td>0.469467</td>\n",
       "      <td>0.503145</td>\n",
       "      <td>0.48137</td>\n",
       "      <td>0.411671</td>\n",
       "      <td>0.374035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AdaBoost        DT       KNN  Logistic    MLP_NN  \\\n",
       "Model Accuracy_cnt   0.73400  0.725000  0.718000  0.760000  0.714000   \n",
       "F1 Score_cnt         0.28048  0.043938  0.136006  0.463224  0.469467   \n",
       "\n",
       "                          NB  Passive Aggresive        RF       SVM  \n",
       "Model Accuracy_cnt  0.760000            0.71700  0.741000  0.678000  \n",
       "F1 Score_cnt        0.503145            0.48137  0.411671  0.374035  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1 = {'Passive Aggresive':score_cnt_pa,'Logistic':score_cnt_lr,'AdaBoost':score_cnt_ada,'NB':score_cnt_nb,\n",
    "       'RF':score_cnt_rf,'DT':score_cnt_dt,'KNN':score_cnt_knn,\"MLP_NN\":score_cnt_mlp,\"SVM\":score_cnt_svm1}\n",
    "\n",
    "F1_cnt = {'Passive Aggresive':F1_pa_cnt,'Logistic':F1_lr_cnt,'AdaBoost':F1_ada_cnt,'NB':F1_nb_cnt,\n",
    "          'RF':F1_rf_cnt,'DT':F1_dt_cnt,'KNN':F1_knn_cnt,\"MLP_NN\":F1_mlp_cnt,\"SVM\":F1_svm_cnt}\n",
    "acc_cnt = pd.DataFrame([acc1,F1_cnt])\n",
    "acc_cnt.index=['Model Accuracy_cnt','F1 Score_cnt']\n",
    "acc_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>DT</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>MLP_NN</th>\n",
       "      <th>NB</th>\n",
       "      <th>Passive Aggresive</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model Accuracy_cnt</th>\n",
       "      <td>0.734000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.718000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.741000</td>\n",
       "      <td>0.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score_cnt</th>\n",
       "      <td>0.280480</td>\n",
       "      <td>0.043938</td>\n",
       "      <td>0.136006</td>\n",
       "      <td>0.463224</td>\n",
       "      <td>0.469467</td>\n",
       "      <td>0.503145</td>\n",
       "      <td>0.481370</td>\n",
       "      <td>0.411671</td>\n",
       "      <td>0.374035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Accuracy_tfidf</th>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>0.703202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score_tfidf</th>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.427453</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.487146</td>\n",
       "      <td>0.479353</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.511945</td>\n",
       "      <td>0.319109</td>\n",
       "      <td>0.498420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      AdaBoost        DT       KNN  Logistic    MLP_NN  \\\n",
       "Model Accuracy_cnt    0.734000  0.725000  0.718000  0.760000  0.714000   \n",
       "F1 Score_cnt          0.280480  0.043938  0.136006  0.463224  0.469467   \n",
       "Model Accuracy_tfidf  0.729000  0.710000  0.720000  0.725000  0.714000   \n",
       "F1 Score_tfidf        0.232804  0.427453  0.063963  0.487146  0.479353   \n",
       "\n",
       "                            NB  Passive Aggresive        RF       SVM  \n",
       "Model Accuracy_cnt    0.760000           0.717000  0.741000  0.678000  \n",
       "F1 Score_cnt          0.503145           0.481370  0.411671  0.374035  \n",
       "Model Accuracy_tfidf  0.738000           0.733000  0.743000  0.703202  \n",
       "F1 Score_tfidf        0.129082           0.511945  0.319109  0.498420  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = acc_cnt\n",
    "performance.append(acc_tfidf, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
